advanced:
  auto_optimize_index: true
  index_refresh_interval: 3600
  max_cached_results: 1000
  optimize_interval: 86400
  whoosh_mem_limit: 512
file_scanner:
  exclude_patterns: .git;.svn;.hg;__pycache__;.idea;.vscode;node_modules;venv;env;.DS_Store;Thumbs.db
  file_types:
    archive: .zip,.rar,.7z,.tar,.gz
    # audio: .mp3,.wav,.flac,.ogg,.m4a
    code: .py,.js,.java,.cpp,.c,.h,.cs,.go,.rs,.php,.rb,.swift
    document: .txt,.md,.pdf,.doc,.docx,.xls,.xlsx,.ppt,.pptx,.csv,.json,.xml
    # image: .jpg,.jpeg,.png,.gif,.bmp,.tiff,.svg
    # video: .mp4,.avi,.mov,.mkv,.wmv
  max_file_size: 100
  recursive: true
  scan_paths: 'D:\\Garbage\\Career\\Senior\\Thesis'
  scan_threads: 4
interface:
  auto_save_settings: true
  font_size: 12
  language: zh_CN
  max_preview_size: 5242880
  result_columns:
  - 文件名
  - 路径
  - 匹配度
  - 修改时间
  splitter_pos: 300
  theme: light
embedding:
  enabled: true
  provider: modelscope
  model_name: iic/nlp_gte_sentence-embedding_chinese-base
  cache_dir: data/models/
  similarity_threshold: 0.7  # 语义相似度阈值
  batch_size: 8  # 批处理大小，用于向量化计算

ai_model:
  enabled: true
  interface_type: wsl  # 可选值: wsl, api
  api_format: openai_chat
  api_url: http://127.0.0.1:8080/v1/chat/completions
  api_model: wsl
  api_key: ''
  system_prompt: |
    你是一名专业的中文文档助理。请根据下方的【文档集合】回答用户的【问题】。
    规则：
    1. 严格基于文档内容回答，不要编造。
    2. 如果用户询问某人、某事出现在哪里，或者询问来源，请务必列出对应的文件名。
    3. 如果答案仅出现在文件名中（例如文件名包含查询词），请明确指出该文件。
    4. 如果文档中没有相关信息，请直接说明未找到。
  max_tokens: 4096
  temperature: 0.6
  request_timeout: 600
  use_gpu: true

rag:
  max_docs: 3  # 增加文档数量以提供更多上下文
  max_context_chars: 4000  # 增加上下文长度以支持更详细的内容
  max_context_chars_total: 8000  # 增加总上下文长度
  max_history_turns: 3
  max_history_chars: 1000
  max_output_tokens: 2048  # 适配Qwen3-4B模型
  temperature: 0.5  # 调整温度以获得更好的响应
  top_p: 0.9
  frequency_penalty: 0.2
  presence_penalty: 0.2
  repetition_penalty: 1.1  # 增加重复惩罚以减少重复内容
  prompt_template: |
    你是一名专业的中文文档分析助理。请基于【文档集合】中的内容，对用户的【问题】提供一个连贯、流畅、总结性的回答。

    核心要求：
    1. 严格基于文档内容回答，不得编造任何信息。
    2. 将相关信息整合成一个连贯的段落，而非分点列表。
    3. 突出关键信息和核心内容，提供综合性的总结。
    4. 对于人物、研究、技术等主题，提供背景、方法、成果等的完整概述。
    5. 如需引用来源，请在回答中自然提及文档名称，而非单独列出。
    6. 重点提取技术细节、研究方法、实现方案、实验结果等知识性内容。
    7. 对于多个文档的信息，进行有机整合，形成统一的叙述。
    8. 避免机械重复文档原文，而是进行概括和总结。
    9. 确保回答逻辑清晰、语句通顺，形成完整的信息实体描述。

    【文档集合】:
    {context}

    【问题】: {question}

    请提供一个连贯、总结性的回答：
  context_exhausted_response: "对话过长，为避免超出上下文，请说‘重置’或简要概括后再继续。"
  reset_response: "已清空上下文，可以重新开始提问。"
  fallback_response: |
    我在本地索引中暂时没有找到与" {query} "直接对应的正文内容。
    你可以：
    1. 再提供更具体的描述（如文件名、章节、作者、时间等）；
    2. 指明文件类型或格式，例如"PDF 报告""Word 文档"；
    3. 如果需要的是操作指南或检索策略，也欢迎直接告诉我，我会给出建议。
    告诉我更详细的线索后，我会立即在全部已扫描文件中再次检索。
  greeting_response: |
    你好呀，我是 FileTools Copilot，本地文件的智能助手。
    我可以帮你搜索 PDF、Word、PPT 甚至代码，把结果整理成摘要或问答。
    需要查资料、找报告要点、生成概览或者验证内容都可以直接告诉我。
    只要说出关键词或问题，我就能立刻从本地库里找到相关内容。
  greeting_keywords:
    - 你好
    - 您好
    - hi
    - hello
    - 嗨
    - 嘿
    - 在吗
    - 在不
  reset_commands:
    - 重置
    - 清空上下文
    - reset
    - restart
monitor:
  debounce_time: 0.5
  directories: 'D:\\Garbage\\Career\\Senior\\Thesis'
  enabled: true
  ignored_patterns: .git;.svn;.hg;__pycache__;.idea;.vscode;node_modules;venv;env;.DS_Store;Thumbs.db
  refresh_interval: 1
search:
  cache_ttl: 3600
  highlight: true
  max_results: 50
  min_score: 0.3
  text_weight: 0.6  # 增加文本搜索权重，提高精确匹配
  vector_weight: 0.4  # 降低向量搜索权重，减少不相关语义匹配
  bm25_k1: 1.5  # BM25参数，控制词频饱和度
  bm25_b: 0.75  # BM25参数，控制文档长度标准化
  result_boost: true  # 启用结果增强
  filename_boost: 1.5  # 文件名匹配增强系数
  keyword_boost: 1.2  # 关键词匹配增强系数
  hybrid_boost: 1.1  # 混合搜索结果增强系数
system:
  app_name: 智能文件检索与问答系统
  cache_dir: ./data/cache
  data_dir: ./data
  index_dir: ./data/index
  log_backup_count: 5
  log_dir: ./data/logs
  log_level: INFO
  log_max_size: 10
  log_rotation: midnight
  log_format: structured
  log_json: false
  log_sensitive_data: false
  temp_dir: ./data/temp
  version: 1.0.0

index:
  tantivy_path: ./data/tantivy_index
  hnsw_path: ./data/hnsw_index
  metadata_path: ./data/metadata