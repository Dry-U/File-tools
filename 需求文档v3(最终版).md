## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 é¡¹ç›®èƒŒæ™¯

éšç€æœ¬åœ°çŸ¥è¯†ç®¡ç†ä¸éšç§ä¿æŠ¤éœ€æ±‚æå‡ï¼Œç”¨æˆ·éœ€è¦**å®Œå…¨ç¦»çº¿è¿è¡Œ**çš„æ™ºèƒ½æ–‡æ¡£é—®ç­”ç³»ç»Ÿã€‚ç°æœ‰æ–¹æ¡ˆå­˜åœ¨ï¼š

- ğŸ’¬ æ— ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›
    
- ğŸŒ ä¾èµ–äº‘ç«¯æœåŠ¡ï¼Œéšç§é£é™©é«˜
    
- ğŸ§¾ æ— æ³•å¤„ç†åˆ†æ•£åœ¨å¤šä¸ªè·¯å¾„çš„æœ¬åœ°æ–‡æ¡£
    

> æœ¬é¡¹ç›®å¼€å‘å¯åœ¨ä¸»æµæ¸¸æˆæœ¬ä¸Šå®Œå…¨ç¦»çº¿è¿è¡Œçš„æ™ºèƒ½æ–‡æ¡£é—®ç­”ç³»ç»Ÿï¼Œå…·å¤‡ç±»ä¼¼Everythingçš„å¿«é€Ÿæ–‡ä»¶ç´¢å¼•èƒ½åŠ›ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡å‹å®ç°æ™ºèƒ½é—®ç­”ã€‚

### 1.2 æ ¸å¿ƒç‰¹æ€§

|ç‰¹æ€§|æè¿°|
|---|---|
|**æ™ºèƒ½æ–‡ä»¶å‘ç°**|è‡ªåŠ¨æ‰«æè¯†åˆ«ç”¨æˆ·æ–‡æ¡£ï¼Œè¿‡æ»¤ç³»ç»Ÿæ–‡ä»¶|
|**é—ªç”µçº§ç´¢å¼•**|ç±»ä¼¼Everythingçš„å®æ—¶æ–‡ä»¶ç´¢å¼•æŠ€æœ¯|
|**ç¦»çº¿AIé—®ç­”**|åŸºäºæœ¬åœ°å¤§æ¨¡å‹çš„è¯­ä¹‰ç†è§£ä¸é—®ç­”|
|**å†›ç”¨çº§éšç§**|AES-256åŠ å¯†å­˜å‚¨ï¼Œæ•æ„Ÿæ•°æ®è„±æ•å¤„ç†|
|**å¤šæ ¼å¼æ”¯æŒ**|PDF/DOCX/XLSX/TXT/Markdown/ä»£ç æ–‡ä»¶|

### 1.3 ç›®æ ‡ç¡¬ä»¶é…ç½®

|é…ç½®çº§åˆ«|CPU|å†…å­˜|æ˜¾å¡|å­˜å‚¨|
|---|---|---|---|---|
|**æœ€ä½é…ç½®**|i5-10ä»£/R5-4600H|16GB|GTX 1650/RTX 3050|256GB SSD|
|**æ¨èé…ç½®**|i7-12ä»£/R7-5800H|32GB|RTX 3060/4060|512GB SSD|
|**ç†æƒ³é…ç½®**|i9-13ä»£/R9-7940H|64GB|RTX 4070/4080|1TB NVMe|

### 1.4 æ¨èæœ¬åœ°æ¨¡å‹æ–¹æ¡ˆ

|æ¨¡å‹|æ¨ç†é€Ÿåº¦|æ˜¾å­˜å ç”¨|ä¸­æ–‡èƒ½åŠ›|é€‚ç”¨åœºæ™¯|
|---|---|---|---|---|
|**Mistral-7B-Instruct**|20-25 tokens/s|4.5GB|â­â­â­â­|é€šç”¨ä»»åŠ¡|
|**Qwen-7B-Chat**|18-22 tokens/s|4.2GB|â­â­â­â­â­|ä¸­æ–‡æ–‡æ¡£|
|**Phi-3-mini-4k**|35-40 tokens/s|2.8GB|â­â­â­|èµ„æºå—é™|
|**Nous-Hermes-2**|30-35 tokens/s|6.5GB|â­â­â­â­â­|ä¸“ä¸šæ–‡æ¡£|


```python
class ModelManager:
    def auto_select_model(self) -> str:
        """æ ¹æ®ç¡¬ä»¶èµ„æºè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹"""
        vram = self.get_available_vram()
        cpu_cores = os.cpu_count()'''
	    if vram >= 8 * 1024**3 and cpu_cores >= 8:
            return "nous-hermes-2-7b.Q4_K_M.gguf"
        elif vram >= 6 * 1024**3:
            return "mistral-7b-instruct-v0.2.Q5_K_M.gguf"
        elif vram >= 4 * 1024**3:
            return "qwen-7b-chat-v1.5.Q4_K_S.gguf"
        elif cpu_cores >= 6:
            return "phi-3-mini-4k-instruct.Q5_K_M.gguf"
        else:
            return "tinyllama-1.1b.Q8_0.gguf"
```

## 2. ç³»ç»Ÿæ¶æ„è®¾è®¡

### 2.1 æ•´ä½“æ¶æ„

å›¾è¡¨
![fillstoolç³»ç»Ÿæ¶æ„.png](https://img.dar1an.dpdns.org/Picgo/2025/20250708013457694.png)

ä»£ç 

```
graph LR
    A[ç”¨æˆ·ç•Œé¢] --> B[APIç½‘å…³]
    B --> C[æ–‡ä»¶ç›‘æ§æœåŠ¡]
    B --> D[æŸ¥è¯¢å¤„ç†å™¨]
    C --> E[ç´¢å¼•ç®¡ç†å™¨]
    E --> F[æ–‡æ¡£å¤„ç†å™¨]
    F --> G[å‘é‡åŒ–å¼•æ“]
    D --> H[æ£€ç´¢å¼•æ“]
    H --> I[LLMæ¨ç†æœåŠ¡]
    
    subgraph å­˜å‚¨å±‚
        J[æ–‡ä»¶ç´¢å¼•DB]
        K[å‘é‡ç´¢å¼•]
        L[å…ƒæ•°æ®å­˜å‚¨]
        M[æ¨¡å‹ä»“åº“]
    end
    
    E --> J
    G --> K
    F --> L
    I --> M
```
### 2.2 æ ¸å¿ƒæ¨¡å—è¯´æ˜

|æ¨¡å—|åŠŸèƒ½|æŠ€æœ¯é€‰å‹|åˆ›æ–°ç‚¹|
|---|---|---|---|
|**æ™ºèƒ½æ–‡ä»¶ç›‘æ§**|å®æ—¶æ„ŸçŸ¥æ–‡ä»¶å˜åŒ–|USN Journal+inotify|å¢é‡ç´¢å¼•æŠ€æœ¯|
|**å¤šæ ¼å¼è§£æå™¨**|æ–‡æ¡£å†…å®¹æå–|Tika+PyPDF2+pandoc|OCRé›†æˆ|
|**è¯­ä¹‰åˆ†å—å¼•æ“**|ä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†å—|Sentence-BERT|è¡¨æ ¼/ä»£ç ä¿ç•™|
|**æ··åˆæ£€ç´¢ç³»ç»Ÿ**|è¯­ä¹‰+å…³é”®è¯æœç´¢|FAISS+BM25|åŠ¨æ€æƒé‡è°ƒæ•´|
|**è‡ªé€‚åº”æ¨ç†**|æœ¬åœ°LLMè°ƒåº¦|llama.cpp+vLLM|æ˜¾å­˜æ„ŸçŸ¥åŠ è½½|

## 3. åŠŸèƒ½éœ€æ±‚è¯¦è§£

### 3.1 æ–‡ä»¶ç³»ç»Ÿæ‰«æï¼ˆå¢å¼ºï¼‰

#### 3.1.1 æ™ºèƒ½æ–‡ä»¶è¯†åˆ«

```python

class FileScanner:
    # æ”¯æŒæ–‡ä»¶ç±»å‹æ‰©å±•
    TARGET_EXTENSIONS = {
        'documents': ['.pdf', '.doc', '.docx', '.txt', '.md', '.rtf', '.odt'],
        'spreadsheets': ['.xls', '.xlsx', '.csv', '.ods'],
        'presentations': ['.ppt', '.pptx', '.odp'],
        'images': ['.jpg', '.png', '.tiff'],
        'code': ['.py', '.js', '.java', '.cpp', '.go', '.rs', '.vue']
    }
    
    # é«˜çº§æ’é™¤è§„åˆ™
    EXCLUDE_PATTERNS = [
        r'Windows\\', r'Program Files', r'ProgramData', r'\/System',
        r'\/var\/log', r'\/etc', r'\.git', r'node_modules', r'__pycache__'
    ]
    
    def _is_system_file(self, path: str) -> bool:
        """é«˜çº§ç³»ç»Ÿæ–‡ä»¶æ£€æµ‹"""
        if platform.system() == 'Windows':
            if re.search(r'\$[A-Za-z]', path):
                return True
        
        if any(part.startswith('.') and part != '.' for part in Path(path).parts):
            return True
        
        with open(path, 'rb') as f:
            header = f.read(4)
            if header in [b'MZ\x90\x00', b'\x7fELF']:
                return True
        
        return False
```
#### 3.1.2 å¢é‡ç´¢å¼•ä¼˜åŒ–

```python

class SmartIndexer:
    def __init__(self):
        self.change_buffer = deque(maxlen=1000)
        self.last_index_time = time.time()
    
    def process_changes(self):
        if len(self.change_buffer) >= 500 or time.time() - self.last_index_time > 300:
            self._bulk_index()
            self.last_index_time = time.time()
    
    def _bulk_index(self):
        with self.db.transaction():
            for action in self.change_buffer:
                if action['type'] == 'update':
                    self._update_index(action['path'])
                elif action['type'] == 'delete':
                    self._remove_from_index(action['path'])
        self.change_buffer.clear()
```
### 3.2 æ–‡æ¡£å¤„ç†æµæ°´çº¿

#### 3.2.1 å¤šæ ¼å¼è§£æå™¨ï¼ˆå¢å¼ºï¼‰

```python

class UniversalParser:
    SUPPORTED_MIME_TYPES = {
        'application/pdf': PDFParser,
        'application/vnd.openxmlformats-officedocument.wordprocessingml.document': DocxParser,
        'text/plain': TextParser,
        'text/markdown': MarkdownParser,
        'image/jpeg': OCRParser,
        'image/png': OCRParser
    }
    
    def parse(self, file_path: str) -> Document:
        mime_type = self.detect_mime_type(file_path)
        parser_class = self.SUPPORTED_MIME_TYPES.get(mime_type, self.FallbackParser)
        
        try:
            content = parser_class().extract(file_path)
            return self.post_process(content, file_path)
        except Exception as e:
            logger.error(f"è§£æå¤±è´¥ {file_path}: {e}")
            return None
    
    def post_process(self, content: str, file_path: str) -> Document:
        content = self.remove_header_footer(content)
        content = self.preserve_tables(content)
        
        if Path(file_path).suffix in ['.py', '.js', '.java']:
            content = self.preserve_code_blocks(content)
        
        return Document(content)
```
### 3.3 AIé—®ç­”åŠŸèƒ½ï¼ˆå¢å¼ºï¼‰

#### 3.3.1 æ··åˆæ£€ç´¢å¼•æ“

```python

class HybridRetriever:
    def search(self, query: str, top_k: int = 5) -> List[Document]:
        with ThreadPoolExecutor() as executor:
            vector_future = executor.submit(self.vector_retriever.search, query, top_k*2)
            keyword_future = executor.submit(self.keyword_retriever.search, query, top_k*2)
        
        vector_results = vector_future.result()
        keyword_results = keyword_future.result()
        
        combined = self.rerank_results(query, vector_results + keyword_results)
        return combined[:top_k]
    
    def rerank_results(self, query: str, candidates: List[Document]) -> List[Document]:
        scores = self.cross_encoder.predict([(query, doc.content) for doc in candidates])
        sorted_indices = np.argsort(scores)[::-1]
        return [candidates[i] for i in sorted_indices]
```
## 4. æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆï¼ˆå¢å¼ºï¼‰

### 4.1 æ˜¾å­˜ä¼˜åŒ–ç­–ç•¥

```python

class VRAMManager:
    def load_model(self, model_name: str) -> Llama:
        model_size = self.get_model_size(model_name)
        
        if model_size > self.available_vram():
            self.release_unused_models()
            if model_size > self.available_vram():
                return self.load_quantized_model(model_name)
        
        model = Llama(
            model_path=model_name,
            n_gpu_layers=-1,
            n_ctx=4096,
            seed=42
        )
        self.model_cache[model_name] = {
            'model': model,
            'last_used': time.time(),
            'size': model_size
        }
        self.current_vram += model_size
        return model
    
    def release_unused_models(self, timeout=600):
        current_time = time.time()
        for name, info in list(self.model_cache.items()):
            if current_time - info['last_used'] > timeout:
                del info['model']
                self.current_vram -= info['size']
                del self.model_cache[name]
```
### 4.2 æ¨ç†åŠ é€ŸæŠ€æœ¯

```python

class InferenceOptimizer:
    def generate(self, prompt: str, session_id: str = None) -> Generator:
        if session_id in self.kv_cache:
            return self._generate_with_cache(prompt, session_id)
        
        if self.batch_processor.can_batch():
            return self.batch_processor.add_request(prompt)
        
        return self._single_inference(prompt)
    
    def _generate_with_cache(self, prompt: str, session_id: str) -> Generator:
        cache = self.kv_cache[session_id]
        for token in self.model.generate(prompt, past_key_values=cache, use_cache=True):
            yield token
        self.kv_cache[session_id] = self.model.current_key_values()
```
## 5. éåŠŸèƒ½æ€§éœ€æ±‚

### 5.1 å®‰å…¨ä¸éšç§ä¿éšœ

|å®‰å…¨æªæ–½|è¯´æ˜|
|---|---|
|**å­˜å‚¨å®‰å…¨**|AES-256åŠ å¯†å­˜å‚¨|
|**ä¼ è¾“å®‰å…¨**|HTTPS + JWTé‰´æƒ|
|**è®¿é—®æ§åˆ¶**|RBACè§’è‰²æƒé™ç³»ç»Ÿ|
|**æ•°æ®è„±æ•**|æ­£åˆ™+æœºå™¨å­¦ä¹ è¯†åˆ«|
|**å®¡è®¡è¿½è¸ª**|ä¸å¯å˜æ—¥å¿—å­˜å‚¨|

```python

class PrivacyFilter:
    SENSITIVE_PATTERNS = {
        'id_card': r'\b[1-9]\d{5}(?:18|19|20)\d{2}(?:0[1-9]|1[0-2])(?:0[1-9]|[12]\d|3[01])\d{3}[\dXx]\b',
        'phone': r'\b1[3-9]\d{9}\b',
        'bank_card': r'\b[1-9]\d{9,17}\b',
        'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    }
    
    def sanitize(self, text: str) -> str:
        for key, pattern in self.SENSITIVE_PATTERNS.items():
            text = re.sub(pattern, f'[{key.upper()}_REDACTED]', text)
        
        entities = self.ner_model.predict(text)
        for ent in entities:
            if ent['entity'] in ['PERSON', 'ORG', 'LOC']:
                text = text.replace(ent['word'], f"[{ent['entity']}_REDACTED]")
        
        return text
```
### 5.2 æ€§èƒ½çº¦æŸ

|æ¨¡å—|P99å»¶è¿Ÿ|ååé‡|èµ„æºé™åˆ¶|
|---|---|---|---|
|æ–‡æ¡£åµŒå…¥|â‰¤1.5s|20MB/åˆ†é’Ÿ|CPU<80%, RAM<6G|
|æŸ¥è¯¢å“åº”|â‰¤2s|-|æ˜¾å­˜<7GB|
|å‘é‡æ£€ç´¢|â‰¤300ms|50 QPS|-|

### 5.3 å¹³å°å…¼å®¹æ€§

|ç³»ç»Ÿå¹³å°|å¯è¿è¡Œæ€§|å¤‡æ³¨|
|---|---|---|
|Windows 11|âœ…|NVIDIA RTX 20+|
|macOS 13+|âœ…|M1/M2èŠ¯ç‰‡|
|Ubuntu 22.04|âœ…|CUDA/ROCm|
|Raspberry Pi|âŒ|æ¨ç†å›°éš¾|

## 6. ç”¨æˆ·ç•Œé¢è®¾è®¡

### 6.1 æ¡Œé¢åº”ç”¨ç•Œé¢

```typescript

interface MainWindow {
    FileExplorer: {
        showIndexedFiles: boolean;
        filterByType: string[];
        sortBy: 'name' | 'date' | 'size';
    };
    
    ChatInterface: {
        messages: Message[];
        inputBox: string;
        showSources: boolean;
    };
    
    StatusBar: {
        indexedFiles: number;
        modelStatus: 'loading' | 'ready' | 'error';
        gpuUsage: number;
        memoryUsage: number;
    };
}
```
### 6.2 è®¾ç½®ç•Œé¢

```typescript

interface SettingsWindow {
    FileScanning: {
        includePaths: string[];
        excludePaths: string[];
        fileTypes: string[];
        scanInterval: number;
    };
    
    ModelConfig: {
        selectedModel: string;
        downloadedModels: ModelInfo[];
        autoSelectModel: boolean;
        maxGpuMemory: number;
    };
    
    Performance: {
        maxCpuThreads: number;
        enableGpuAcceleration: boolean;
        cacheSize: number;
        batchSize: number;
    };
}
```
## 7. éƒ¨ç½²æ–¹æ¡ˆï¼ˆå¤šå¹³å°æ”¯æŒï¼‰

### 7.1 Windowså®‰è£…è„šæœ¬

```powershell

# install.ps1
param([string]$InstallPath = "$env:LOCALAPPDATA\DocAssistant")
Write-Host "æœ¬åœ°æ–‡æ¡£åŠ©æ‰‹å®‰è£…ç¨‹åº" -ForegroundColor Green

$ram = (Get-WmiObject Win32_ComputerSystem).TotalPhysicalMemory / 1GB
if ($ram -lt 16) { Write-Warning "ç³»ç»Ÿå†…å­˜å°äº16GBï¼Œå¯èƒ½å½±å“æ€§èƒ½" }

New-Item -ItemType Directory -Force -Path $InstallPath
New-Item -ItemType Directory -Force -Path "$InstallPath\models"

Invoke-WebRequest -Uri "https://release-url/DocAssistant.exe" -OutFile "$InstallPath\DocAssistant.exe"

$WshShell = New-Object -comObject WScript.Shell
$Shortcut = $WshShell.CreateShortcut("$env:DESKTOP\æ–‡æ¡£åŠ©æ‰‹.lnk")
$Shortcut.TargetPath = "$InstallPath\DocAssistant.exe"
$Shortcut.Save()
```
### 7.2 Docker Composeé…ç½®

```yaml

version: '3.8'
services:
  doc-assistant:
    image: docassistant:5.0
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    volumes:
      - ./models:/app/models
      - ./data:/app/data
      - ~/Documents:/documents:ro
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - OMP_NUM_THREADS=8
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```
## 8. é…ç½®ç®¡ç†

### 8.1 ä¸»é…ç½®æ–‡ä»¶ (config.yaml)

```yaml

system:
  data_dir: "./data"
  log_level: "INFO"

file_scanner:
  scan_paths:
    - "~/Documents"
    - "~/Downloads"
  exclude_patterns:
    - ".*\\.git"
    - ".*node_modules"
  file_types:
    documents: [".pdf", ".doc", ".docx", ".txt", ".md"]
  max_file_size: 100

model:
  model_dir: "./models"
  default_model: "auto"
  inference:
    max_context_length: 4096
    temperature: 0.7
    use_gpu: true
```
## 9. APIæ¥å£è§„èŒƒ

### 9.1 RESTful API

```yaml

paths:
  /api/v1/query:
    post:
      summary: æ‰§è¡Œæ™ºèƒ½æŸ¥è¯¢
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                query:
                  type: string
                file_filter:
                  type: array
                  items: string
      responses:
        200:
          content:
            application/json:
              schema:
                type: object
                properties:
                  answer:
                    type: string
                  sources:
                    type: array
                    items: string
```
## 10. æµ‹è¯•æ–¹æ¡ˆï¼ˆå¢å¼ºï¼‰

### 10.1 æ€§èƒ½åŸºå‡†æµ‹è¯•

```python

class PerformanceBenchmark:
    def test_scalability(self):
        for scale in [1_000, 10_000, 100_000]:
            test_dir = self.generate_test_data(scale)
            
            start = time.monotonic()
            indexer.build_index(test_dir)
            index_time = time.monotonic() - start
            
            query_times = []
            for query in TEST_QUERIES:
                start = time.monotonic()
                retriever.search(query)
                query_times.append(time.monotonic() - start)
            
            mem_usage = psutil.Process().memory_info().rss / 1024**2
            
            self.results[f"scale_{scale}"] = {
                'index_time': index_time,
                'avg_query_time': np.mean(query_times),
                'max_memory': mem_usage
            }
```
### 10.2 è‡ªåŠ¨åŒ–æµ‹è¯•ç”¨ä¾‹

```python

def test_rag_workflow():
    system = DocumentAssistant()
    system.index_directory("sample_data")
    
    response = system.query("æ–‡æ¡£ä¸­çš„å…³é”®æ¡æ¬¾æ˜¯ä»€ä¹ˆï¼Ÿ")
    
    assert "ä¿å¯†åè®®" in response['answer']
    assert len(response['sources']) > 0
```
## 11. é¡¹ç›®è®¡åˆ’ä¸è¿­ä»£

### 11.1 å¼€å‘é‡Œç¨‹ç¢‘

|é˜¶æ®µ|æ—¶é—´å‘¨æœŸ|ç›®æ ‡|
|---|---|---|
|Alpha|ç¬¬1-4å‘¨|æ–‡ä»¶ç›‘æ§+æ–‡æ¡£ç´¢å¼•|
|Beta|ç¬¬5-8å‘¨|RAGé—®ç­”+æœ¬åœ°LLM|
|RC|ç¬¬9-10å‘¨|å®‰å…¨ç­–ç•¥+æ€§èƒ½ä¼˜åŒ–|

### 11.2 é£é™©åº”å¯¹

|é£é™©|è§£å†³æ–¹æ¡ˆ|
|---|---|
|æ¨¡å‹åŠ è½½å¤±è´¥|è‡ªåŠ¨fallbackåˆ°è½»é‡æ¨¡å‹|
|è®¾å¤‡èµ„æºä¸è¶³|åŠ¨æ€é€‰æ‹©æ¨¡å‹é‡åŒ–çº§åˆ«|
|æ£€ç´¢ä¸å‡†|æç¤ºä¼˜åŒ–é—®æ³•+æ‘˜è¦fallback|

## 12. äº¤ä»˜ç‰©æ¸…å•

### 12.1 æŠ€æœ¯äº¤ä»˜

1. **æ ¸å¿ƒç¨‹åº**
    
    - DocAssistant.exe (Windows)
        
    - è·¨å¹³å°Dockeré•œåƒ
        
2. **æ¨¡å‹æ–‡ä»¶**
    
    - mistral-7b-instruct-v0.2.Q4_K_M.gguf
        
    - nous-hermes-2-7b.Q4_K_M.gguf
        
3. **æ–‡æ¡£èµ„æ–™**
    
    - ç”¨æˆ·æ‰‹å†Œ
        
    - éƒ¨ç½²æŒ‡å—
        
    - APIæ–‡æ¡£
        

### 12.2 è¾…åŠ©å·¥å…·

- ç³»ç»Ÿè¯Šæ–­å·¥å…·
    
- æ¨¡å‹è½¬æ¢CLIï¼š
    
    bash
    
    $ model-builder convert --input checkpoint.pt --quant q4_k_m
    

## é™„å½•Aï¼šæœ¯è¯­è§£é‡Š

|æœ¯è¯­|è¯´æ˜|
|---|---|
|RAG|æ£€ç´¢å¢å¼ºç”Ÿæˆ|
|GGUF|llama.cppé‡åŒ–æ ¼å¼|
|KV Cache|LLMé•¿æœŸä¸Šä¸‹æ–‡ä¿æŒæŠ€æœ¯|
|Q4_K_M|4ä½æ•´æ•°é‡åŒ–+KVæ”¯æŒ|