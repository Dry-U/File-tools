## 1. 项目概述

### 1.1 项目背景

随着本地知识管理与隐私保护需求提升，用户需要**完全离线运行**的智能文档问答系统。现有方案存在：

- 💬 无上下文推理能力
    
- 🌐 依赖云端服务，隐私风险高
    
- 🧾 无法处理分散在多个路径的本地文档
    

> 本项目开发可在主流游戏本上完全离线运行的智能文档问答系统，具备类似Everything的快速文件索引能力，结合大语言模型实现智能问答。

### 1.2 核心特性

|特性|描述|
|---|---|
|**智能文件发现**|自动扫描识别用户文档，过滤系统文件|
|**闪电级索引**|类似Everything的实时文件索引技术|
|**离线AI问答**|基于本地大模型的语义理解与问答|
|**军用级隐私**|AES-256加密存储，敏感数据脱敏处理|
|**多格式支持**|PDF/DOCX/XLSX/TXT/Markdown/代码文件|

### 1.3 目标硬件配置

|配置级别|CPU|内存|显卡|存储|
|---|---|---|---|---|
|**最低配置**|i5-10代/R5-4600H|16GB|GTX 1650/RTX 3050|256GB SSD|
|**推荐配置**|i7-12代/R7-5800H|32GB|RTX 3060/4060|512GB SSD|
|**理想配置**|i9-13代/R9-7940H|64GB|RTX 4070/4080|1TB NVMe|

### 1.4 推荐本地模型方案

|模型|推理速度|显存占用|中文能力|适用场景|
|---|---|---|---|---|
|**Mistral-7B-Instruct**|20-25 tokens/s|4.5GB|⭐⭐⭐⭐|通用任务|
|**Qwen-7B-Chat**|18-22 tokens/s|4.2GB|⭐⭐⭐⭐⭐|中文文档|
|**Phi-3-mini-4k**|35-40 tokens/s|2.8GB|⭐⭐⭐|资源受限|
|**Nous-Hermes-2**|30-35 tokens/s|6.5GB|⭐⭐⭐⭐⭐|专业文档|


```python
class ModelManager:
    def auto_select_model(self) -> str:
        """根据硬件资源自动选择最优模型"""
        vram = self.get_available_vram()
        cpu_cores = os.cpu_count()'''
	    if vram >= 8 * 1024**3 and cpu_cores >= 8:
            return "nous-hermes-2-7b.Q4_K_M.gguf"
        elif vram >= 6 * 1024**3:
            return "mistral-7b-instruct-v0.2.Q5_K_M.gguf"
        elif vram >= 4 * 1024**3:
            return "qwen-7b-chat-v1.5.Q4_K_S.gguf"
        elif cpu_cores >= 6:
            return "phi-3-mini-4k-instruct.Q5_K_M.gguf"
        else:
            return "tinyllama-1.1b.Q8_0.gguf"
```

## 2. 系统架构设计

### 2.1 整体架构

图表
![fillstool系统架构.png](https://img.dar1an.dpdns.org/Picgo/2025/20250708013457694.png)

代码

```
graph LR
    A[用户界面] --> B[API网关]
    B --> C[文件监控服务]
    B --> D[查询处理器]
    C --> E[索引管理器]
    E --> F[文档处理器]
    F --> G[向量化引擎]
    D --> H[检索引擎]
    H --> I[LLM推理服务]
    
    subgraph 存储层
        J[文件索引DB]
        K[向量索引]
        L[元数据存储]
        M[模型仓库]
    end
    
    E --> J
    G --> K
    F --> L
    I --> M
```
### 2.2 核心模块说明

|模块|功能|技术选型|创新点|
|---|---|---|---|
|**智能文件监控**|实时感知文件变化|USN Journal+inotify|增量索引技术|
|**多格式解析器**|文档内容提取|Tika+PyPDF2+pandoc|OCR集成|
|**语义分块引擎**|上下文感知分块|Sentence-BERT|表格/代码保留|
|**混合检索系统**|语义+关键词搜索|FAISS+BM25|动态权重调整|
|**自适应推理**|本地LLM调度|llama.cpp+vLLM|显存感知加载|

## 3. 功能需求详解

### 3.1 文件系统扫描（增强）

#### 3.1.1 智能文件识别

```python

class FileScanner:
    # 支持文件类型扩展
    TARGET_EXTENSIONS = {
        'documents': ['.pdf', '.doc', '.docx', '.txt', '.md', '.rtf', '.odt'],
        'spreadsheets': ['.xls', '.xlsx', '.csv', '.ods'],
        'presentations': ['.ppt', '.pptx', '.odp'],
        'images': ['.jpg', '.png', '.tiff'],
        'code': ['.py', '.js', '.java', '.cpp', '.go', '.rs', '.vue']
    }
    
    # 高级排除规则
    EXCLUDE_PATTERNS = [
        r'Windows\\', r'Program Files', r'ProgramData', r'\/System',
        r'\/var\/log', r'\/etc', r'\.git', r'node_modules', r'__pycache__'
    ]
    
    def _is_system_file(self, path: str) -> bool:
        """高级系统文件检测"""
        if platform.system() == 'Windows':
            if re.search(r'\$[A-Za-z]', path):
                return True
        
        if any(part.startswith('.') and part != '.' for part in Path(path).parts):
            return True
        
        with open(path, 'rb') as f:
            header = f.read(4)
            if header in [b'MZ\x90\x00', b'\x7fELF']:
                return True
        
        return False
```
#### 3.1.2 增量索引优化

```python

class SmartIndexer:
    def __init__(self):
        self.change_buffer = deque(maxlen=1000)
        self.last_index_time = time.time()
    
    def process_changes(self):
        if len(self.change_buffer) >= 500 or time.time() - self.last_index_time > 300:
            self._bulk_index()
            self.last_index_time = time.time()
    
    def _bulk_index(self):
        with self.db.transaction():
            for action in self.change_buffer:
                if action['type'] == 'update':
                    self._update_index(action['path'])
                elif action['type'] == 'delete':
                    self._remove_from_index(action['path'])
        self.change_buffer.clear()
```
### 3.2 文档处理流水线

#### 3.2.1 多格式解析器（增强）

```python

class UniversalParser:
    SUPPORTED_MIME_TYPES = {
        'application/pdf': PDFParser,
        'application/vnd.openxmlformats-officedocument.wordprocessingml.document': DocxParser,
        'text/plain': TextParser,
        'text/markdown': MarkdownParser,
        'image/jpeg': OCRParser,
        'image/png': OCRParser
    }
    
    def parse(self, file_path: str) -> Document:
        mime_type = self.detect_mime_type(file_path)
        parser_class = self.SUPPORTED_MIME_TYPES.get(mime_type, self.FallbackParser)
        
        try:
            content = parser_class().extract(file_path)
            return self.post_process(content, file_path)
        except Exception as e:
            logger.error(f"解析失败 {file_path}: {e}")
            return None
    
    def post_process(self, content: str, file_path: str) -> Document:
        content = self.remove_header_footer(content)
        content = self.preserve_tables(content)
        
        if Path(file_path).suffix in ['.py', '.js', '.java']:
            content = self.preserve_code_blocks(content)
        
        return Document(content)
```
### 3.3 AI问答功能（增强）

#### 3.3.1 混合检索引擎

```python

class HybridRetriever:
    def search(self, query: str, top_k: int = 5) -> List[Document]:
        with ThreadPoolExecutor() as executor:
            vector_future = executor.submit(self.vector_retriever.search, query, top_k*2)
            keyword_future = executor.submit(self.keyword_retriever.search, query, top_k*2)
        
        vector_results = vector_future.result()
        keyword_results = keyword_future.result()
        
        combined = self.rerank_results(query, vector_results + keyword_results)
        return combined[:top_k]
    
    def rerank_results(self, query: str, candidates: List[Document]) -> List[Document]:
        scores = self.cross_encoder.predict([(query, doc.content) for doc in candidates])
        sorted_indices = np.argsort(scores)[::-1]
        return [candidates[i] for i in sorted_indices]
```
## 4. 性能优化方案（增强）

### 4.1 显存优化策略

```python

class VRAMManager:
    def load_model(self, model_name: str) -> Llama:
        model_size = self.get_model_size(model_name)
        
        if model_size > self.available_vram():
            self.release_unused_models()
            if model_size > self.available_vram():
                return self.load_quantized_model(model_name)
        
        model = Llama(
            model_path=model_name,
            n_gpu_layers=-1,
            n_ctx=4096,
            seed=42
        )
        self.model_cache[model_name] = {
            'model': model,
            'last_used': time.time(),
            'size': model_size
        }
        self.current_vram += model_size
        return model
    
    def release_unused_models(self, timeout=600):
        current_time = time.time()
        for name, info in list(self.model_cache.items()):
            if current_time - info['last_used'] > timeout:
                del info['model']
                self.current_vram -= info['size']
                del self.model_cache[name]
```
### 4.2 推理加速技术

```python

class InferenceOptimizer:
    def generate(self, prompt: str, session_id: str = None) -> Generator:
        if session_id in self.kv_cache:
            return self._generate_with_cache(prompt, session_id)
        
        if self.batch_processor.can_batch():
            return self.batch_processor.add_request(prompt)
        
        return self._single_inference(prompt)
    
    def _generate_with_cache(self, prompt: str, session_id: str) -> Generator:
        cache = self.kv_cache[session_id]
        for token in self.model.generate(prompt, past_key_values=cache, use_cache=True):
            yield token
        self.kv_cache[session_id] = self.model.current_key_values()
```
## 5. 非功能性需求

### 5.1 安全与隐私保障

|安全措施|说明|
|---|---|
|**存储安全**|AES-256加密存储|
|**传输安全**|HTTPS + JWT鉴权|
|**访问控制**|RBAC角色权限系统|
|**数据脱敏**|正则+机器学习识别|
|**审计追踪**|不可变日志存储|

```python

class PrivacyFilter:
    SENSITIVE_PATTERNS = {
        'id_card': r'\b[1-9]\d{5}(?:18|19|20)\d{2}(?:0[1-9]|1[0-2])(?:0[1-9]|[12]\d|3[01])\d{3}[\dXx]\b',
        'phone': r'\b1[3-9]\d{9}\b',
        'bank_card': r'\b[1-9]\d{9,17}\b',
        'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    }
    
    def sanitize(self, text: str) -> str:
        for key, pattern in self.SENSITIVE_PATTERNS.items():
            text = re.sub(pattern, f'[{key.upper()}_REDACTED]', text)
        
        entities = self.ner_model.predict(text)
        for ent in entities:
            if ent['entity'] in ['PERSON', 'ORG', 'LOC']:
                text = text.replace(ent['word'], f"[{ent['entity']}_REDACTED]")
        
        return text
```
### 5.2 性能约束

|模块|P99延迟|吞吐量|资源限制|
|---|---|---|---|
|文档嵌入|≤1.5s|20MB/分钟|CPU<80%, RAM<6G|
|查询响应|≤2s|-|显存<7GB|
|向量检索|≤300ms|50 QPS|-|

### 5.3 平台兼容性

|系统平台|可运行性|备注|
|---|---|---|
|Windows 11|✅|NVIDIA RTX 20+|
|macOS 13+|✅|M1/M2芯片|
|Ubuntu 22.04|✅|CUDA/ROCm|
|Raspberry Pi|❌|推理困难|

## 6. 用户界面设计

### 6.1 桌面应用界面

```typescript

interface MainWindow {
    FileExplorer: {
        showIndexedFiles: boolean;
        filterByType: string[];
        sortBy: 'name' | 'date' | 'size';
    };
    
    ChatInterface: {
        messages: Message[];
        inputBox: string;
        showSources: boolean;
    };
    
    StatusBar: {
        indexedFiles: number;
        modelStatus: 'loading' | 'ready' | 'error';
        gpuUsage: number;
        memoryUsage: number;
    };
}
```
### 6.2 设置界面

```typescript

interface SettingsWindow {
    FileScanning: {
        includePaths: string[];
        excludePaths: string[];
        fileTypes: string[];
        scanInterval: number;
    };
    
    ModelConfig: {
        selectedModel: string;
        downloadedModels: ModelInfo[];
        autoSelectModel: boolean;
        maxGpuMemory: number;
    };
    
    Performance: {
        maxCpuThreads: number;
        enableGpuAcceleration: boolean;
        cacheSize: number;
        batchSize: number;
    };
}
```
## 7. 部署方案（多平台支持）

### 7.1 Windows安装脚本

```powershell

# install.ps1
param([string]$InstallPath = "$env:LOCALAPPDATA\DocAssistant")
Write-Host "本地文档助手安装程序" -ForegroundColor Green

$ram = (Get-WmiObject Win32_ComputerSystem).TotalPhysicalMemory / 1GB
if ($ram -lt 16) { Write-Warning "系统内存小于16GB，可能影响性能" }

New-Item -ItemType Directory -Force -Path $InstallPath
New-Item -ItemType Directory -Force -Path "$InstallPath\models"

Invoke-WebRequest -Uri "https://release-url/DocAssistant.exe" -OutFile "$InstallPath\DocAssistant.exe"

$WshShell = New-Object -comObject WScript.Shell
$Shortcut = $WshShell.CreateShortcut("$env:DESKTOP\文档助手.lnk")
$Shortcut.TargetPath = "$InstallPath\DocAssistant.exe"
$Shortcut.Save()
```
### 7.2 Docker Compose配置

```yaml

version: '3.8'
services:
  doc-assistant:
    image: docassistant:5.0
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    volumes:
      - ./models:/app/models
      - ./data:/app/data
      - ~/Documents:/documents:ro
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - OMP_NUM_THREADS=8
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```
## 8. 配置管理

### 8.1 主配置文件 (config.yaml)

```yaml

system:
  data_dir: "./data"
  log_level: "INFO"

file_scanner:
  scan_paths:
    - "~/Documents"
    - "~/Downloads"
  exclude_patterns:
    - ".*\\.git"
    - ".*node_modules"
  file_types:
    documents: [".pdf", ".doc", ".docx", ".txt", ".md"]
  max_file_size: 100

model:
  model_dir: "./models"
  default_model: "auto"
  inference:
    max_context_length: 4096
    temperature: 0.7
    use_gpu: true
```
## 9. API接口规范

### 9.1 RESTful API

```yaml

paths:
  /api/v1/query:
    post:
      summary: 执行智能查询
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                query:
                  type: string
                file_filter:
                  type: array
                  items: string
      responses:
        200:
          content:
            application/json:
              schema:
                type: object
                properties:
                  answer:
                    type: string
                  sources:
                    type: array
                    items: string
```
## 10. 测试方案（增强）

### 10.1 性能基准测试

```python

class PerformanceBenchmark:
    def test_scalability(self):
        for scale in [1_000, 10_000, 100_000]:
            test_dir = self.generate_test_data(scale)
            
            start = time.monotonic()
            indexer.build_index(test_dir)
            index_time = time.monotonic() - start
            
            query_times = []
            for query in TEST_QUERIES:
                start = time.monotonic()
                retriever.search(query)
                query_times.append(time.monotonic() - start)
            
            mem_usage = psutil.Process().memory_info().rss / 1024**2
            
            self.results[f"scale_{scale}"] = {
                'index_time': index_time,
                'avg_query_time': np.mean(query_times),
                'max_memory': mem_usage
            }
```
### 10.2 自动化测试用例

```python

def test_rag_workflow():
    system = DocumentAssistant()
    system.index_directory("sample_data")
    
    response = system.query("文档中的关键条款是什么？")
    
    assert "保密协议" in response['answer']
    assert len(response['sources']) > 0
```
## 11. 项目计划与迭代

### 11.1 开发里程碑

|阶段|时间周期|目标|
|---|---|---|
|Alpha|第1-4周|文件监控+文档索引|
|Beta|第5-8周|RAG问答+本地LLM|
|RC|第9-10周|安全策略+性能优化|

### 11.2 风险应对

|风险|解决方案|
|---|---|
|模型加载失败|自动fallback到轻量模型|
|设备资源不足|动态选择模型量化级别|
|检索不准|提示优化问法+摘要fallback|

## 12. 交付物清单

### 12.1 技术交付

1. **核心程序**
    
    - DocAssistant.exe (Windows)
        
    - 跨平台Docker镜像
        
2. **模型文件**
    
    - mistral-7b-instruct-v0.2.Q4_K_M.gguf
        
    - nous-hermes-2-7b.Q4_K_M.gguf
        
3. **文档资料**
    
    - 用户手册
        
    - 部署指南
        
    - API文档
        

### 12.2 辅助工具

- 系统诊断工具
    
- 模型转换CLI：
    
    bash
    
    $ model-builder convert --input checkpoint.pt --quant q4_k_m
    

## 附录A：术语解释

|术语|说明|
|---|---|
|RAG|检索增强生成|
|GGUF|llama.cpp量化格式|
|KV Cache|LLM长期上下文保持技术|
|Q4_K_M|4位整数量化+KV支持|